# ğŸ¬ RAG YouTube Video Chatting App

An AI-powered multilingual chatbot built with Retrieval-Augmented Generation (RAG) that answers questions based on YouTube video transcripts. The system uses **Gemma 2** for generation and **`intfloat/multilingual-e5-large`** for semantic embeddings, enabling accurate and context-rich responses in multiple languages.

---

## ğŸš€ Features

- ğŸŒ **Multilingual Embeddings**: Supports multiple languages with `intfloat/multilingual-e5-large`
- ğŸ¬ **YouTube Transcript Analysis**: Interact with YouTube video content through natural conversation
- ğŸ§  **Gemma 2 LLM**: Lightweight open-source language model for fast, high-quality responses
- ğŸ” **Semantic Search**: Retrieves relevant transcript segments using vector similarity
- âš¡ **RAG Pipeline**: Combines retrieval and generation for deep contextual understanding
- ğŸ’¾ **ChromaDB Vector Store**: Efficient similarity search using in-memory or persisted vectors

---

## ğŸ“ Project Structure

rag-youtube-chat-app/
â”œâ”€â”€ yt_components/
â”‚ â”œâ”€â”€ retriver.py # Document retriever using ChromaDB
â”‚ â”œâ”€â”€ embedder.py # Loads and applies E5 embedding model
â”‚ â”œâ”€â”€ query.py # Core RAG logic: retrieval + generation
â”œâ”€â”€ transcripts/ # Saved YouTube transcripts
â”œâ”€â”€ main.py # Main application runner
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This documentation


---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/rag-youtube-chat-app.git
cd rag-youtube-chat-app


2. Create and Activate Environment
bash
Copy
Edit
conda create -n rag-env python=3.10 -y
conda activate rag-env
3. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
4. Configure Environment Variables
Create a .env file in the root directory:

env
Copy
Edit
HUGGINGFACEHUB_API_TOKEN=your_huggingface_token_here
ğŸ” How It Works
Transcript Loading: Load local or fetched YouTube transcripts.

Embedding: Use intfloat/multilingual-e5-large to convert transcripts into semantic vectors.

Vector Store: Store these vectors in ChromaDB for similarity search.

Retrieval: Retrieve the most relevant transcript chunks using vector similarity.

Generation: Feed the retrieved context and user query to Gemma 2 to generate a natural response.

ğŸ’¬ Example Usage
python
Copy
Edit
# main.py

query = "What did the speaker say about transformers?"
response = chain.invoke({
    "query": query,
    "context": context
})
print(response)
âœ… To-Do
 Auto-download YouTube transcripts via youtube_transcript_api

 Build a Streamlit or Gradio frontend for UI

 Support for multi-video document collections

 Dockerize for scalable deployment

 GPU acceleration for local Gemma 2 inference

ğŸ§  Models Used
Component	Model Name	Source
Language Model	Gemma 2B or Gemma 2B IT	Gemma on Hugging Face
Embeddings	intfloat/multilingual-e5-large	E5 Model
Vector Store	ChromaDB	Chroma

ğŸ“š Dependencies
langchain

chromadb

transformers

sentence-transformers

torch

youtube-transcript-api

python-dotenv

ğŸ‘¨â€ğŸ’» Author
Nitish Kumar
Built using open models and community-driven tools to make AI video understanding more accessible.

ğŸ“œ License
This project is licensed under the MIT License.
See the LICENSE file for details.

yaml
Copy
Edit

---


